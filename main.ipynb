{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b07d279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/disi/miniconda3/lib/python3.12/site-packages (4.53.2)\n",
      "Requirement already satisfied: filelock in /home/disi/miniconda3/lib/python3.12/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /home/disi/miniconda3/lib/python3.12/site-packages (from transformers) (0.32.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/disi/miniconda3/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/disi/miniconda3/lib/python3.12/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/disi/miniconda3/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/disi/miniconda3/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /home/disi/miniconda3/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/disi/miniconda3/lib/python3.12/site-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/disi/miniconda3/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/disi/miniconda3/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/disi/miniconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/disi/miniconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /home/disi/miniconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/disi/miniconda3/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/disi/miniconda3/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/disi/miniconda3/lib/python3.12/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/disi/miniconda3/lib/python3.12/site-packages (from requests->transformers) (2025.7.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cb16e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in /home/disi/miniconda3/lib/python3.12/site-packages (8.1.7)\n",
      "Requirement already satisfied: comm>=0.1.3 in /home/disi/miniconda3/lib/python3.12/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /home/disi/miniconda3/lib/python3.12/site-packages (from ipywidgets) (9.4.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/disi/miniconda3/lib/python3.12/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in /home/disi/miniconda3/lib/python3.12/site-packages (from ipywidgets) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /home/disi/miniconda3/lib/python3.12/site-packages (from ipywidgets) (3.0.15)\n",
      "Requirement already satisfied: decorator in /home/disi/miniconda3/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in /home/disi/miniconda3/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/disi/miniconda3/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /home/disi/miniconda3/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/disi/miniconda3/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /home/disi/miniconda3/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/disi/miniconda3/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (2.15.1)\n",
      "Requirement already satisfied: stack_data in /home/disi/miniconda3/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in /home/disi/miniconda3/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /home/disi/miniconda3/lib/python3.12/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/disi/miniconda3/lib/python3.12/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/disi/miniconda3/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/disi/miniconda3/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in /home/disi/miniconda3/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ipywidgets\n",
    "\n",
    "from huggingface_hub import login\n",
    "login(\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a03b47e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hf_xet in /home/disi/miniconda3/lib/python3.12/site-packages (1.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "%pip install hf_xet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27cdf0a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/disi/miniconda3/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: torchvision in /home/disi/miniconda3/lib/python3.12/site-packages (0.17.2)\n",
      "Requirement already satisfied: transformers in /home/disi/miniconda3/lib/python3.12/site-packages (4.53.2)\n",
      "Requirement already satisfied: accelerate in /home/disi/miniconda3/lib/python3.12/site-packages (1.8.1)\n",
      "Requirement already satisfied: bitsandbytes in /home/disi/miniconda3/lib/python3.12/site-packages (0.46.1)\n",
      "Requirement already satisfied: pandas in /home/disi/miniconda3/lib/python3.12/site-packages (2.3.1)\n",
      "Requirement already satisfied: openpyxl in /home/disi/miniconda3/lib/python3.12/site-packages (3.1.5)\n",
      "Requirement already satisfied: filelock in /home/disi/miniconda3/lib/python3.12/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/disi/miniconda3/lib/python3.12/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /home/disi/miniconda3/lib/python3.12/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/disi/miniconda3/lib/python3.12/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/disi/miniconda3/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/disi/miniconda3/lib/python3.12/site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/disi/miniconda3/lib/python3.12/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/disi/miniconda3/lib/python3.12/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/disi/miniconda3/lib/python3.12/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/disi/miniconda3/lib/python3.12/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/disi/miniconda3/lib/python3.12/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/disi/miniconda3/lib/python3.12/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/disi/miniconda3/lib/python3.12/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/disi/miniconda3/lib/python3.12/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/disi/miniconda3/lib/python3.12/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/disi/miniconda3/lib/python3.12/site-packages (from torch) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/disi/miniconda3/lib/python3.12/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/disi/miniconda3/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.85)\n",
      "Requirement already satisfied: numpy in /home/disi/miniconda3/lib/python3.12/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/disi/miniconda3/lib/python3.12/site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /home/disi/miniconda3/lib/python3.12/site-packages (from transformers) (0.32.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/disi/miniconda3/lib/python3.12/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/disi/miniconda3/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/disi/miniconda3/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /home/disi/miniconda3/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/disi/miniconda3/lib/python3.12/site-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/disi/miniconda3/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/disi/miniconda3/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /home/disi/miniconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.2)\n",
      "Requirement already satisfied: psutil in /home/disi/miniconda3/lib/python3.12/site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/disi/miniconda3/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/disi/miniconda3/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/disi/miniconda3/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: et-xmlfile in /home/disi/miniconda3/lib/python3.12/site-packages (from openpyxl) (2.0.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/disi/miniconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/disi/miniconda3/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/disi/miniconda3/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/disi/miniconda3/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/disi/miniconda3/lib/python3.12/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/disi/miniconda3/lib/python3.12/site-packages (from requests->transformers) (2025.7.9)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/disi/miniconda3/lib/python3.12/site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision transformers accelerate bitsandbytes pandas openpyxl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f30f1bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load Excel\n",
    "df = pd.read_excel(\"tp_2017conference.xlsx\")\n",
    "\n",
    "# Drop rows missing title/abstract/review\n",
    "df = df.dropna(subset=[\"title\", \"abstract\", \"review\"])\n",
    "\n",
    "# Clean abstract field\n",
    "df[\"abstract\"] = df[\"abstract\"].str.replace(\"Abstract:###\", \"\", regex=False).str.strip()\n",
    "\n",
    "# Deduplicate by title (merge reviews)\n",
    "grouped = df.groupby(\"title\").agg({\n",
    "    \"abstract\": \"first\",  # assume same abstract\n",
    "    \"review\": lambda r: \"\\n\\n\".join(r),  # concat reviews\n",
    "    \"rate\": list,\n",
    "    \"confidence\": list,\n",
    "    \"decision\": \"first\"\n",
    "}).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0e3f15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_val, test = train_test_split(grouped, test_size=0.2, random_state=42)\n",
    "train, val = train_test_split(train_val, test_size=0.1, random_state=42)\n",
    "\n",
    "# Save for future use\n",
    "train.to_csv(\"train.csv\", index=False)\n",
    "val.to_csv(\"val.csv\", index=False)\n",
    "test.to_csv(\"test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdabd9ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25f0e9cdb3fd4e8ba7069fdd64639374",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import torch\n",
    "\n",
    "model_name = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",  # 👈 now this will choose GPU\n",
    "    quantization_config=bnb_config,\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d433f93d",
   "metadata": {},
   "source": [
    "ZERO-SHOT BASELINE EVAL:\n",
    "Here’s the template structure you should follow (based on the format Llama models expect):\n",
    "\n",
    "prompt = f\"\"\"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
    "Title: {paper_title}\n",
    "Abstract: {paper_abstract}\n",
    "What are the main strengths and weaknesses of this paper?<|eot_id|>\n",
    "<|start_header_id|>assistant<|end_header_id|>\"\"\"\n",
    "\n",
    "\n",
    "In training, your target (label) will be the review_summary (or the review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d24e587",
   "metadata": {},
   "source": [
    "First you need to clean the dataset to deduplicate the papers (group by title, take first abstract, and merge reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9691831",
   "metadata": {},
   "source": [
    "1. Generate Zero-Shot Predictions\n",
    "Use your cleaned dataset to prompt the base model without fine-tuning, and generate its assessment for each paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03720e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_zero_shot(paper):\n",
    "    prompt = f\"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\"\n",
    "    prompt += f\"Title: {paper['title']}\\nAbstract: {paper['abstract']}\\n\"\n",
    "    prompt += \"What are the strengths and weaknesses of this paper?<|eot_id|>\\n\"\n",
    "    prompt += \"<|start_header_id|>assistant<|end_header_id|>\\n\"\n",
    "\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=256,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            do_sample=False, # Faster, deterministic\n",
    "            temperature=1.0,\n",
    "            top_p=1.0\n",
    "        )\n",
    "\n",
    "    decoded = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
    "    response = decoded.split(\"<|start_header_id|>assistant<|end_header_id|>\\n\")[-1]\n",
    "    return response.strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bafc13f",
   "metadata": {},
   "source": [
    "Sequential GPU inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa90ef07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating zero-shot reviews for 98 test papers\n",
      "[1/98] Training deep neural-networks using a noise adaptation layer...\n",
      "   ✅ Done in 12.33s\n",
      "[2/98] Deep Character-Level Neural Machine Translation By Learning ...\n",
      "   ✅ Done in 11.71s\n",
      "[3/98] Third Person Imitation Learning | OpenReview...\n",
      "   ✅ Done in 11.68s\n",
      "[4/98] Unsupervised Learning of State Representations for Multiple ...\n",
      "   ✅ Done in 11.72s\n",
      "[5/98] The Neural Noisy Channel | OpenReview...\n",
      "   ✅ Done in 11.64s\n",
      "[6/98] New Learning Approach By Genetic Algorithm In A Convolutiona...\n",
      "   ✅ Done in 11.63s\n",
      "[7/98] An Actor-Critic Algorithm for Sequence Prediction | OpenRevi...\n",
      "   ✅ Done in 11.69s\n",
      "[8/98] Joint Training of Ratings and Reviews with Recurrent Recomme...\n",
      "   ✅ Done in 11.68s\n",
      "[9/98] What Is the Best Practice for CNNs Applied to Visual Instanc...\n",
      "   ✅ Done in 11.66s\n",
      "[10/98] Learning Efficient Algorithms with Hierarchical Attentive Me...\n",
      "   ✅ Done in 11.54s\n",
      "[11/98] A Learned Representation For Artistic Style | OpenReview...\n",
      "   ✅ Done in 11.56s\n",
      "[12/98] Dynamic Steerable Frame Networks | OpenReview...\n",
      "   ✅ Done in 11.69s\n",
      "[13/98] Tartan: Accelerating Fully-Connected and Convolutional Layer...\n",
      "   ✅ Done in 11.51s\n",
      "[14/98] Incorporating long-range consistency in CNN-based texture ge...\n",
      "   ✅ Done in 11.57s\n",
      "[15/98] Recurrent Coevolutionary Feature Embedding Processes for Rec...\n",
      "   ✅ Done in 11.56s\n",
      "[16/98] Communicating Hierarchical Neural Controllers for Learning Z...\n",
      "   ✅ Done in 11.39s\n",
      "[17/98] The Predictron: End-To-End Learning and Planning | OpenRevie...\n",
      "   ✅ Done in 11.27s\n",
      "[18/98] The Preimage of Rectifier Network Activities | OpenReview...\n",
      "   ✅ Done in 11.26s\n",
      "[19/98] Recurrent Mixture Density Network for Spatiotemporal Visual ...\n",
      "   ✅ Done in 11.27s\n",
      "[20/98] Intelligible Language Modeling with Input Switched Affine Ne...\n",
      "   ✅ Done in 11.28s\n",
      "[21/98] DRAGNN: A Transition-Based Framework for Dynamically Connect...\n",
      "   ✅ Done in 11.23s\n",
      "[22/98] Gradients of Counterfactuals | OpenReview...\n",
      "   ✅ Done in 11.13s\n",
      "[23/98] Tensorial Mixture Models | OpenReview...\n",
      "   ✅ Done in 11.11s\n",
      "[24/98] CONTENT2VEC: SPECIALIZING JOINT REPRESENTATIONS OF PRODUCT I...\n",
      "   ✅ Done in 11.11s\n",
      "[25/98] Cortical-Inspired Open-Bigram Representation for Handwritten...\n",
      "   ✅ Done in 11.23s\n",
      "[26/98] Counterpoint by Convolution | OpenReview...\n",
      "   ✅ Done in 11.15s\n",
      "[27/98] FILTER SHAPING FOR CONVOLUTIONAL NEURAL NETWORKS | OpenRevie...\n",
      "   ✅ Done in 11.12s\n",
      "[28/98] Lie-Access Neural Turing Machines | OpenReview...\n",
      "   ✅ Done in 11.15s\n",
      "[29/98] Lossy Image Compression with Compressive Autoencoders | Open...\n",
      "   ✅ Done in 11.13s\n",
      "[30/98] Riemannian Optimization for Skip-Gram Negative Sampling | Op...\n",
      "   ✅ Done in 11.24s\n",
      "[31/98] DeepCoder: Learning to Write Programs | OpenReview...\n",
      "   ✅ Done in 11.35s\n",
      "[32/98] EPOpt: Learning Robust Neural Network Policies Using Model E...\n",
      "   ✅ Done in 11.13s\n",
      "[33/98] Nonparametric Neural Networks | OpenReview...\n",
      "   ✅ Done in 11.13s\n",
      "[34/98] On orthogonality and learning recurrent networks with long t...\n",
      "   ✅ Done in 11.15s\n",
      "[35/98] An Analysis of Feature Regularization for Low-shot Learning ...\n",
      "   ✅ Done in 11.16s\n",
      "[36/98] Conditional Image Synthesis With Auxiliary Classifier GANs |...\n",
      "   ✅ Done in 11.07s\n",
      "[37/98] #Exploration: A Study of Count-Based Exploration for Deep Re...\n",
      "   ✅ Done in 11.07s\n",
      "[38/98] A Neural Stochastic Volatility Model | OpenReview...\n",
      "   ✅ Done in 11.11s\n",
      "[39/98] Learning Curve Prediction with Bayesian Neural Networks | Op...\n",
      "   ✅ Done in 11.04s\n",
      "[40/98] HyperNetworks | OpenReview...\n",
      "   ✅ Done in 11.06s\n",
      "[41/98] Skip-graph: Learning graph embeddings with an encoder-decode...\n",
      "   ✅ Done in 11.09s\n",
      "[42/98] Semi-supervised Knowledge Transfer for Deep Learning from Pr...\n",
      "   ✅ Done in 11.08s\n",
      "[43/98] Song From PI: A Musically Plausible Network for Pop Music Ge...\n",
      "   ✅ Done in 11.04s\n",
      "[44/98] Extrapolation and learning equations | OpenReview...\n",
      "   ✅ Done in 11.14s\n",
      "[45/98] Combating Deep Reinforcement Learning*s Sisyphean Curse with...\n",
      "   ✅ Done in 11.35s\n",
      "[46/98] Identity Matters in Deep Learning | OpenReview...\n",
      "   ✅ Done in 11.25s\n",
      "[47/98] A recurrent neural network without chaos | OpenReview...\n",
      "   ✅ Done in 11.28s\n",
      "[48/98] Towards a Neural Statistician | OpenReview...\n",
      "   ✅ Done in 11.14s\n",
      "[49/98] What does it take to generate natural textures? | OpenReview...\n",
      "   ✅ Done in 11.14s\n",
      "[50/98] Warped Convolutions: Efficient Invariance to Spatial Transfo...\n",
      "   ✅ Done in 11.11s\n",
      "[51/98] The Incredible Shrinking Neural Network: New Perspectives on...\n",
      "   ✅ Done in 11.09s\n",
      "[52/98] Attentive Recurrent Comparators | OpenReview...\n",
      "   ✅ Done in 11.19s\n",
      "[53/98] Generating Long and Diverse Responses with Neural Conversati...\n",
      "   ✅ Done in 11.10s\n",
      "[54/98] Neural Data Filter for Bootstrapping Stochastic Gradient Des...\n",
      "   ✅ Done in 11.12s\n",
      "[55/98] Fast Adaptation in Generative Models with Generative Matchin...\n",
      "   ✅ Done in 11.12s\n",
      "[56/98] Compositional Kernel Machines | OpenReview...\n",
      "   ✅ Done in 11.10s\n",
      "[57/98] Two Methods for Wild Variational Inference | OpenReview...\n",
      "   ✅ Done in 11.13s\n",
      "[58/98] Deep Predictive Coding Networks for Video Prediction and Uns...\n",
      "   ✅ Done in 11.04s\n",
      "[59/98] Optimization as a Model for Few-Shot Learning | OpenReview...\n",
      "   ✅ Done in 11.13s\n",
      "[60/98] Exploring LOTS in Deep Neural Networks | OpenReview...\n",
      "   ✅ Done in 11.11s\n",
      "[61/98] Why Deep Neural Networks for Function Approximation? | OpenR...\n",
      "   ✅ Done in 11.06s\n",
      "[62/98] The Concrete Distribution: A Continuous Relaxation of Discre...\n",
      "   ✅ Done in 11.04s\n",
      "[63/98] Chess Game Concepts Emerge under Weak Supervision: A Case St...\n",
      "   ✅ Done in 11.03s\n",
      "[64/98] Neuro-Symbolic Program Synthesis | OpenReview...\n",
      "   ✅ Done in 11.09s\n",
      "[65/98] Paying More Attention to Attention: Improving the Performanc...\n",
      "   ✅ Done in 11.01s\n",
      "[66/98] Low-rank passthrough neural networks | OpenReview...\n",
      "   ✅ Done in 11.05s\n",
      "[67/98] Deep Learning with Sets and Point Clouds | OpenReview...\n",
      "   ✅ Done in 11.16s\n",
      "[68/98] Learning to Understand: Incorporating Local Contexts with Gl...\n",
      "   ✅ Done in 11.09s\n",
      "[69/98] Sequence to Sequence Transduction with Hard Monotonic Attent...\n",
      "   ✅ Done in 11.11s\n",
      "[70/98] Visualizing Deep Neural Network Decisions: Prediction Differ...\n",
      "   ✅ Done in 11.09s\n",
      "[71/98] Symmetry-Breaking Convergence Analysis of Certain Two-layere...\n",
      "   ✅ Done in 11.07s\n",
      "[72/98] Delving into Transferable Adversarial Examples and Black-box...\n",
      "   ✅ Done in 11.11s\n",
      "[73/98] ParMAC: distributed optimisation of nested functions, with a...\n",
      "   ✅ Done in 11.09s\n",
      "[74/98] Unrolled Generative Adversarial Networks | OpenReview...\n",
      "   ✅ Done in 11.16s\n",
      "[75/98] Unsupervised Pretraining for Sequence to Sequence Learning |...\n",
      "   ✅ Done in 11.11s\n",
      "[76/98] DSD: Dense-Sparse-Dense Training for Deep Neural Networks | ...\n",
      "   ✅ Done in 11.17s\n",
      "[77/98] NEWSQA: A MACHINE COMPREHENSION DATASET | OpenReview...\n",
      "   ✅ Done in 11.16s\n",
      "[78/98] Normalizing the Normalizers: Comparing and Extending Network...\n",
      "   ✅ Done in 11.11s\n",
      "[79/98] Decomposing Motion and Content for Natural Video Sequence Pr...\n",
      "   ✅ Done in 11.18s\n",
      "[80/98] Efficient Summarization with Read-Again and Copy Mechanism |...\n",
      "   ✅ Done in 11.10s\n",
      "[81/98] Neural Taylor Approximations: Convergence and Exploration in...\n",
      "   ✅ Done in 11.14s\n",
      "[82/98] Multi-modal Variational Encoder-Decoders | OpenReview...\n",
      "   ✅ Done in 11.17s\n",
      "[83/98] Semi-Supervised Classification with Graph Convolutional Netw...\n",
      "   ✅ Done in 11.13s\n",
      "[84/98] Vocabulary Selection Strategies for Neural Machine Translati...\n",
      "   ✅ Done in 11.16s\n",
      "[85/98] Divide and Conquer with Neural Networks | OpenReview...\n",
      "   ✅ Done in 11.20s\n",
      "[86/98] Perception Updating Networks: On architectural constraints f...\n",
      "   ✅ Done in 11.08s\n",
      "[87/98] Deep Error-Correcting Output Codes | OpenReview...\n",
      "   ✅ Done in 11.08s\n",
      "[88/98] Cooperative Training of Descriptor and Generator Networks | ...\n",
      "   ✅ Done in 11.15s\n",
      "[89/98] The Power of Sparsity in Convolutional Neural Networks | Ope...\n",
      "   ✅ Done in 11.12s\n",
      "[90/98] A Theoretical Framework for Robustness of (Deep) Classifiers...\n",
      "   ✅ Done in 11.12s\n",
      "[91/98] Inference and Introspection in Deep Generative Models of Spa...\n",
      "   ✅ Done in 11.07s\n",
      "[92/98] Revisiting Classifier Two-Sample Tests | OpenReview...\n",
      "   ✅ Done in 11.08s\n",
      "[93/98] Adaptive Feature Abstraction for Translating Video to Langua...\n",
      "   ✅ Done in 11.12s\n",
      "[94/98] OMG: Orthogonal Method of Grouping With Application of K-Sho...\n",
      "   ✅ Done in 11.11s\n",
      "[95/98] Rethinking Numerical Representations for Deep Neural Network...\n",
      "   ✅ Done in 11.09s\n",
      "[96/98] Calibrating Energy-based Generative Adversarial Networks | O...\n",
      "   ✅ Done in 11.04s\n",
      "[97/98] Machine Solver for Physics Word Problems | OpenReview...\n",
      "   ✅ Done in 11.12s\n",
      "[98/98] Shift Aggregate Extract Networks | OpenReview...\n",
      "   ✅ Done in 11.03s\n",
      "\n",
      "✅ Saved zero-shot reviews for 98 papers.\n",
      "⏱️ Avg generation time: 11.22s\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Load test set\n",
    "test_df = pd.read_csv(\"test.csv\")  # or use the uploaded path\n",
    "print(f\"Generating zero-shot reviews for {len(test_df)} test papers\")\n",
    "\n",
    "# Inference loop\n",
    "preds = []\n",
    "timings = []\n",
    "\n",
    "for i, row in test_df.iterrows():\n",
    "    print(f\"[{i+1}/{len(test_df)}] {row['title'][:60]}...\")\n",
    "\n",
    "    try:\n",
    "        start = time.time()\n",
    "        response = generate_zero_shot(row)\n",
    "        duration = time.time() - start\n",
    "        preds.append(response)\n",
    "        timings.append(duration)\n",
    "        print(f\"   ✅ Done in {duration:.2f}s\")\n",
    "\n",
    "    except Exception as e:\n",
    "        preds.append(f\"[ERROR: {e}]\")\n",
    "        timings.append(None)\n",
    "        print(f\"   ❌ Error: {e}\")\n",
    "\n",
    "# Save\n",
    "test_df[\"zero_shot_review\"] = preds\n",
    "test_df[\"generation_time\"] = timings\n",
    "test_df.to_csv(\"zero_shot_predictions.csv\", index=False)\n",
    "\n",
    "print(f\"\\n✅ Saved zero-shot reviews for {len(test_df)} papers.\")\n",
    "print(f\"⏱️ Avg generation time: {sum(t for t in timings if t) / len(timings):.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22679db3",
   "metadata": {},
   "source": [
    "Fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9457da29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model\n",
    "\n",
    "# Prepare for LoRA fine-tuning\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "609a060e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4713a9d12f17432e998d5064f4aea900",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/351 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b99d395ea0044630a01906dd40bbc829",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/40 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "val_df = pd.read_csv(\"val.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Define prompt formatting function\n",
    "def format_prompt(example):\n",
    "    return {\n",
    "        \"text\": f\"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\"\n",
    "                f\"Title: {example['title']}\\nAbstract: {example['abstract']}\\n\"\n",
    "                \"What are the strengths and weaknesses of this paper?<|eot_id|>\\n\"\n",
    "                \"<|start_header_id|>assistant<|end_header_id|>\\n\"\n",
    "                f\"{example['review']}\"  # ground-truth target\n",
    "    }\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df).map(format_prompt)\n",
    "val_dataset = Dataset.from_pandas(val_df).map(format_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e741c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: peft in /home/disi/miniconda3/lib/python3.12/site-packages (0.16.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/disi/miniconda3/lib/python3.12/site-packages (from peft) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/disi/miniconda3/lib/python3.12/site-packages (from peft) (24.2)\n",
      "Requirement already satisfied: psutil in /home/disi/miniconda3/lib/python3.12/site-packages (from peft) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in /home/disi/miniconda3/lib/python3.12/site-packages (from peft) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.13.0 in /home/disi/miniconda3/lib/python3.12/site-packages (from peft) (2.2.2)\n",
      "Requirement already satisfied: transformers in /home/disi/miniconda3/lib/python3.12/site-packages (from peft) (4.53.2)\n",
      "Requirement already satisfied: tqdm in /home/disi/miniconda3/lib/python3.12/site-packages (from peft) (4.67.1)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /home/disi/miniconda3/lib/python3.12/site-packages (from peft) (1.8.1)\n",
      "Requirement already satisfied: safetensors in /home/disi/miniconda3/lib/python3.12/site-packages (from peft) (0.5.3)\n",
      "Requirement already satisfied: huggingface_hub>=0.25.0 in /home/disi/miniconda3/lib/python3.12/site-packages (from peft) (0.32.2)\n",
      "Requirement already satisfied: filelock in /home/disi/miniconda3/lib/python3.12/site-packages (from huggingface_hub>=0.25.0->peft) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/disi/miniconda3/lib/python3.12/site-packages (from huggingface_hub>=0.25.0->peft) (2025.3.0)\n",
      "Requirement already satisfied: requests in /home/disi/miniconda3/lib/python3.12/site-packages (from huggingface_hub>=0.25.0->peft) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/disi/miniconda3/lib/python3.12/site-packages (from huggingface_hub>=0.25.0->peft) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /home/disi/miniconda3/lib/python3.12/site-packages (from huggingface_hub>=0.25.0->peft) (1.1.2)\n",
      "Requirement already satisfied: sympy in /home/disi/miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/disi/miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/disi/miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/disi/miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/disi/miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/disi/miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/disi/miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/disi/miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/disi/miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/disi/miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/disi/miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/disi/miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/disi/miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/disi/miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/disi/miniconda3/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft) (12.6.85)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/disi/miniconda3/lib/python3.12/site-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/disi/miniconda3/lib/python3.12/site-packages (from requests->huggingface_hub>=0.25.0->peft) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/disi/miniconda3/lib/python3.12/site-packages (from requests->huggingface_hub>=0.25.0->peft) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/disi/miniconda3/lib/python3.12/site-packages (from requests->huggingface_hub>=0.25.0->peft) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/disi/miniconda3/lib/python3.12/site-packages (from requests->huggingface_hub>=0.25.0->peft) (2025.7.9)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/disi/miniconda3/lib/python3.12/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/disi/miniconda3/lib/python3.12/site-packages (from transformers->peft) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/disi/miniconda3/lib/python3.12/site-packages (from transformers->peft) (0.21.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3da1a78f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /home/disi/miniconda3/lib/python3.12/site-packages (4.0.0)\n",
      "Requirement already satisfied: filelock in /home/disi/miniconda3/lib/python3.12/site-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/disi/miniconda3/lib/python3.12/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/disi/miniconda3/lib/python3.12/site-packages (from datasets) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/disi/miniconda3/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/disi/miniconda3/lib/python3.12/site-packages (from datasets) (2.3.1)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/disi/miniconda3/lib/python3.12/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/disi/miniconda3/lib/python3.12/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /home/disi/miniconda3/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/disi/miniconda3/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /home/disi/miniconda3/lib/python3.12/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /home/disi/miniconda3/lib/python3.12/site-packages (from datasets) (0.32.2)\n",
      "Requirement already satisfied: packaging in /home/disi/miniconda3/lib/python3.12/site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/disi/miniconda3/lib/python3.12/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/disi/miniconda3/lib/python3.12/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.14)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/disi/miniconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /home/disi/miniconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/disi/miniconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/disi/miniconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/disi/miniconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/disi/miniconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/disi/miniconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in /home/disi/miniconda3/lib/python3.12/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.7)\n",
      "Requirement already satisfied: typing-extensions>=4.2 in /home/disi/miniconda3/lib/python3.12/site-packages (from aiosignal>=1.4.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /home/disi/miniconda3/lib/python3.12/site-packages (from huggingface-hub>=0.24.0->datasets) (1.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/disi/miniconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/disi/miniconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/disi/miniconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2025.7.9)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/disi/miniconda3/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/disi/miniconda3/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/disi/miniconda3/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/disi/miniconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "298d40a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39c089f2ab934897a4999fb292788603",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/351 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9fdb9be743e4a2fbc3d05468029e5e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/40 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TOKENIZE AND prepare datasets\n",
    "def tokenize_function(example):\n",
    "    tokens= tokenizer(\n",
    "        example[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=512\n",
    "    )\n",
    "    tokens[\"labels\"] = tokens[\"input_ids\"].copy()  # use input_ids as labels\n",
    "    return tokens\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_function)\n",
    "val_dataset = val_dataset.map(tokenize_function)\n",
    "\n",
    "# Remove unused columns\n",
    "train_dataset = train_dataset.remove_columns([\"text\", \"title\", \"abstract\", \"review\"])\n",
    "val_dataset = val_dataset.remove_columns([\"text\", \"title\", \"abstract\", \"review\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "012693e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_53392/1084978049.py:19: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "/home/disi/miniconda3/lib/python3.12/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='528' max='528' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [528/528 05:20, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.687800</td>\n",
       "      <td>2.656981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.621800</td>\n",
       "      <td>2.550092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.673700</td>\n",
       "      <td>2.529684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.560700</td>\n",
       "      <td>2.521019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.567000</td>\n",
       "      <td>2.517606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/disi/miniconda3/lib/python3.12/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/disi/miniconda3/lib/python3.12/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/disi/miniconda3/lib/python3.12/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/disi/miniconda3/lib/python3.12/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/disi/miniconda3/lib/python3.12/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=528, training_loss=2.668295285918496, metrics={'train_runtime': 322.0242, 'train_samples_per_second': 3.27, 'train_steps_per_second': 1.64, 'total_flos': 9132968946696192.0, 'train_loss': 2.668295285918496, 'epoch': 3.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fine-tuning setup with Trainer\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./finetuned-llama3\",\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    eval_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    logging_steps=10,\n",
    "    save_steps=100,\n",
    "    eval_steps=100,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=2e-5,\n",
    "    fp16=True,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07ee06f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(128256, 3072)\n",
       "        (layers): ModuleList(\n",
       "          (0-27): 28 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear4bit(in_features=3072, out_features=8192, bias=False)\n",
       "              (up_proj): Linear4bit(in_features=3072, out_features=8192, bias=False)\n",
       "              (down_proj): Linear4bit(in_features=8192, out_features=3072, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=3072, out_features=128256, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086c39ea",
   "metadata": {},
   "source": [
    "EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0e4b520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c7fbb8cb3af40a98b38d46990986bb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/98 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "# Load test data\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Apply prompt format\n",
    "def format_prompt(example):\n",
    "    return {\n",
    "        \"text\": f\"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\"\n",
    "                f\"Title: {example['title']}\\nAbstract: {example['abstract']}\\n\"\n",
    "                \"What are the strengths and weaknesses of this paper?<|eot_id|>\\n\"\n",
    "                \"<|start_header_id|>assistant<|end_header_id|>\\n\"\n",
    "        # no answer (model must generate it)\n",
    "    }\n",
    "\n",
    "formatted_test = Dataset.from_pandas(test_df).map(format_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06658f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dcfae3376344376abeca31e452da3c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/98 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#tokenize the test set for inference\n",
    "def tokenize_test(example):\n",
    "    return tokenizer(\n",
    "        example[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=512,\n",
    "    )\n",
    "\n",
    "tokenized_test = formatted_test.map(tokenize_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "03920278",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate predictions\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "def generate_review(example):\n",
    "    inputs = tokenizer(example[\"text\"], return_tensors=\"pt\", truncation=True, max_length=512).to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=256,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            do_sample=False,\n",
    "            temperature=1.0,\n",
    "            top_p=1.0\n",
    "        )\n",
    "\n",
    "    decoded = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
    "    return decoded.split(\"<|start_header_id|>assistant<|end_header_id|>\\n\")[-1].strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5310ecd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.use_cache = True\n",
    "model.gradient_checkpointing_disable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c79344f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [29:53<00:00, 18.30s/it]\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Set model to evaluation mode\n",
    "test_predictions = []\n",
    "\n",
    "for example in tqdm(test_df.to_dict(orient=\"records\")):\n",
    "    prompt = format_prompt(example)[\"text\"]\n",
    "\n",
    "    # Tokenize and move to device\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True).to(model.device)\n",
    "\n",
    "    # Inference\n",
    "    with torch.inference_mode():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=256,\n",
    "            do_sample=False,          # deterministic, faster\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            temperature=1.0,\n",
    "            top_p=1.0,\n",
    "            use_cache=True            # ✅ IMPORTANT for speed\n",
    "        )\n",
    "\n",
    "    # Decode the output\n",
    "    decoded = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
    "    response = decoded.split(\"<|start_header_id|>assistant<|end_header_id|>\\n\")[-1]\n",
    "\n",
    "    test_predictions.append(response.strip())\n",
    "\n",
    "# Save predictions\n",
    "test_df[\"generated_review\"] = test_predictions\n",
    "test_df.to_csv(\"finetuned_predictions.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7f757f",
   "metadata": {},
   "source": [
    "EVALUATION WITH REGRESSION METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aeff0c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
