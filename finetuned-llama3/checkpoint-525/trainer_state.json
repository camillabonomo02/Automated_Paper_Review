{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 100,
  "global_step": 525,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.05714285714285714,
      "grad_norm": 0.5570366382598877,
      "learning_rate": 1.9657142857142858e-05,
      "loss": 3.1425,
      "step": 10
    },
    {
      "epoch": 0.11428571428571428,
      "grad_norm": 0.7978075742721558,
      "learning_rate": 1.9276190476190477e-05,
      "loss": 3.1166,
      "step": 20
    },
    {
      "epoch": 0.17142857142857143,
      "grad_norm": 0.6972470879554749,
      "learning_rate": 1.8895238095238096e-05,
      "loss": 3.0004,
      "step": 30
    },
    {
      "epoch": 0.22857142857142856,
      "grad_norm": 0.7107284069061279,
      "learning_rate": 1.8514285714285716e-05,
      "loss": 2.9849,
      "step": 40
    },
    {
      "epoch": 0.2857142857142857,
      "grad_norm": 0.6972787976264954,
      "learning_rate": 1.8133333333333335e-05,
      "loss": 2.8963,
      "step": 50
    },
    {
      "epoch": 0.34285714285714286,
      "grad_norm": 0.7151273488998413,
      "learning_rate": 1.7752380952380954e-05,
      "loss": 2.767,
      "step": 60
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.7054111361503601,
      "learning_rate": 1.7371428571428573e-05,
      "loss": 2.8436,
      "step": 70
    },
    {
      "epoch": 0.45714285714285713,
      "grad_norm": 0.7594277262687683,
      "learning_rate": 1.6990476190476192e-05,
      "loss": 2.7117,
      "step": 80
    },
    {
      "epoch": 0.5142857142857142,
      "grad_norm": 0.8893826007843018,
      "learning_rate": 1.660952380952381e-05,
      "loss": 2.7786,
      "step": 90
    },
    {
      "epoch": 0.5714285714285714,
      "grad_norm": 0.7597888708114624,
      "learning_rate": 1.622857142857143e-05,
      "loss": 2.7501,
      "step": 100
    },
    {
      "epoch": 0.5714285714285714,
      "eval_loss": 2.6160902976989746,
      "eval_runtime": 2.3213,
      "eval_samples_per_second": 17.231,
      "eval_steps_per_second": 8.616,
      "step": 100
    },
    {
      "epoch": 0.6285714285714286,
      "grad_norm": 0.775235116481781,
      "learning_rate": 1.584761904761905e-05,
      "loss": 2.615,
      "step": 110
    },
    {
      "epoch": 0.6857142857142857,
      "grad_norm": 0.7486773729324341,
      "learning_rate": 1.546666666666667e-05,
      "loss": 2.6732,
      "step": 120
    },
    {
      "epoch": 0.7428571428571429,
      "grad_norm": 0.8459116220474243,
      "learning_rate": 1.5085714285714288e-05,
      "loss": 2.6644,
      "step": 130
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.7378285527229309,
      "learning_rate": 1.4704761904761905e-05,
      "loss": 2.6206,
      "step": 140
    },
    {
      "epoch": 0.8571428571428571,
      "grad_norm": 0.8316915035247803,
      "learning_rate": 1.4323809523809525e-05,
      "loss": 2.5806,
      "step": 150
    },
    {
      "epoch": 0.9142857142857143,
      "grad_norm": 0.8581629991531372,
      "learning_rate": 1.3942857142857145e-05,
      "loss": 2.6282,
      "step": 160
    },
    {
      "epoch": 0.9714285714285714,
      "grad_norm": 0.869922399520874,
      "learning_rate": 1.3561904761904763e-05,
      "loss": 2.634,
      "step": 170
    },
    {
      "epoch": 1.0285714285714285,
      "grad_norm": 0.7993678450584412,
      "learning_rate": 1.318095238095238e-05,
      "loss": 2.6872,
      "step": 180
    },
    {
      "epoch": 1.0857142857142856,
      "grad_norm": 0.8677578568458557,
      "learning_rate": 1.2800000000000001e-05,
      "loss": 2.5451,
      "step": 190
    },
    {
      "epoch": 1.1428571428571428,
      "grad_norm": 0.8254417181015015,
      "learning_rate": 1.241904761904762e-05,
      "loss": 2.5843,
      "step": 200
    },
    {
      "epoch": 1.1428571428571428,
      "eval_loss": 2.536309242248535,
      "eval_runtime": 2.3413,
      "eval_samples_per_second": 17.085,
      "eval_steps_per_second": 8.542,
      "step": 200
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.8862216472625732,
      "learning_rate": 1.203809523809524e-05,
      "loss": 2.5612,
      "step": 210
    },
    {
      "epoch": 1.2571428571428571,
      "grad_norm": 0.8098185658454895,
      "learning_rate": 1.1657142857142859e-05,
      "loss": 2.6594,
      "step": 220
    },
    {
      "epoch": 1.3142857142857143,
      "grad_norm": 0.8228567838668823,
      "learning_rate": 1.1276190476190476e-05,
      "loss": 2.5239,
      "step": 230
    },
    {
      "epoch": 1.3714285714285714,
      "grad_norm": 0.946872353553772,
      "learning_rate": 1.0895238095238097e-05,
      "loss": 2.6089,
      "step": 240
    },
    {
      "epoch": 1.4285714285714286,
      "grad_norm": 0.9621862769126892,
      "learning_rate": 1.0514285714285714e-05,
      "loss": 2.6268,
      "step": 250
    },
    {
      "epoch": 1.4857142857142858,
      "grad_norm": 0.8650689721107483,
      "learning_rate": 1.0133333333333335e-05,
      "loss": 2.5811,
      "step": 260
    },
    {
      "epoch": 1.5428571428571427,
      "grad_norm": 0.930003821849823,
      "learning_rate": 9.752380952380953e-06,
      "loss": 2.5116,
      "step": 270
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.9978015422821045,
      "learning_rate": 9.371428571428572e-06,
      "loss": 2.579,
      "step": 280
    },
    {
      "epoch": 1.657142857142857,
      "grad_norm": 0.9686316251754761,
      "learning_rate": 8.990476190476191e-06,
      "loss": 2.6228,
      "step": 290
    },
    {
      "epoch": 1.7142857142857144,
      "grad_norm": 0.9386565089225769,
      "learning_rate": 8.60952380952381e-06,
      "loss": 2.6513,
      "step": 300
    },
    {
      "epoch": 1.7142857142857144,
      "eval_loss": 2.5193169116973877,
      "eval_runtime": 2.3216,
      "eval_samples_per_second": 17.23,
      "eval_steps_per_second": 8.615,
      "step": 300
    },
    {
      "epoch": 1.7714285714285714,
      "grad_norm": 0.9374487996101379,
      "learning_rate": 8.22857142857143e-06,
      "loss": 2.5551,
      "step": 310
    },
    {
      "epoch": 1.8285714285714287,
      "grad_norm": 1.0787569284439087,
      "learning_rate": 7.847619047619048e-06,
      "loss": 2.4704,
      "step": 320
    },
    {
      "epoch": 1.8857142857142857,
      "grad_norm": 1.0297795534133911,
      "learning_rate": 7.4666666666666675e-06,
      "loss": 2.6546,
      "step": 330
    },
    {
      "epoch": 1.9428571428571428,
      "grad_norm": 0.9045237302780151,
      "learning_rate": 7.085714285714286e-06,
      "loss": 2.5736,
      "step": 340
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.9404792785644531,
      "learning_rate": 6.704761904761905e-06,
      "loss": 2.5816,
      "step": 350
    },
    {
      "epoch": 2.057142857142857,
      "grad_norm": 1.1086183786392212,
      "learning_rate": 6.323809523809524e-06,
      "loss": 2.5728,
      "step": 360
    },
    {
      "epoch": 2.1142857142857143,
      "grad_norm": 1.048161506652832,
      "learning_rate": 5.942857142857143e-06,
      "loss": 2.5966,
      "step": 370
    },
    {
      "epoch": 2.1714285714285713,
      "grad_norm": 0.9767370223999023,
      "learning_rate": 5.561904761904763e-06,
      "loss": 2.5746,
      "step": 380
    },
    {
      "epoch": 2.2285714285714286,
      "grad_norm": 1.0464363098144531,
      "learning_rate": 5.180952380952381e-06,
      "loss": 2.5249,
      "step": 390
    },
    {
      "epoch": 2.2857142857142856,
      "grad_norm": 0.9589229822158813,
      "learning_rate": 4.800000000000001e-06,
      "loss": 2.5446,
      "step": 400
    },
    {
      "epoch": 2.2857142857142856,
      "eval_loss": 2.51253080368042,
      "eval_runtime": 2.3184,
      "eval_samples_per_second": 17.253,
      "eval_steps_per_second": 8.627,
      "step": 400
    },
    {
      "epoch": 2.342857142857143,
      "grad_norm": 1.0448365211486816,
      "learning_rate": 4.41904761904762e-06,
      "loss": 2.5099,
      "step": 410
    },
    {
      "epoch": 2.4,
      "grad_norm": 1.0454211235046387,
      "learning_rate": 4.038095238095238e-06,
      "loss": 2.6444,
      "step": 420
    },
    {
      "epoch": 2.4571428571428573,
      "grad_norm": 1.0446786880493164,
      "learning_rate": 3.6571428571428576e-06,
      "loss": 2.6424,
      "step": 430
    },
    {
      "epoch": 2.5142857142857142,
      "grad_norm": 0.9754018783569336,
      "learning_rate": 3.276190476190477e-06,
      "loss": 2.5519,
      "step": 440
    },
    {
      "epoch": 2.571428571428571,
      "grad_norm": 1.0386204719543457,
      "learning_rate": 2.8952380952380955e-06,
      "loss": 2.4894,
      "step": 450
    },
    {
      "epoch": 2.6285714285714286,
      "grad_norm": 1.0668721199035645,
      "learning_rate": 2.5142857142857147e-06,
      "loss": 2.6106,
      "step": 460
    },
    {
      "epoch": 2.685714285714286,
      "grad_norm": 1.0649864673614502,
      "learning_rate": 2.133333333333334e-06,
      "loss": 2.6312,
      "step": 470
    },
    {
      "epoch": 2.742857142857143,
      "grad_norm": 1.1420423984527588,
      "learning_rate": 1.7523809523809525e-06,
      "loss": 2.5443,
      "step": 480
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.9495137333869934,
      "learning_rate": 1.3714285714285717e-06,
      "loss": 2.5354,
      "step": 490
    },
    {
      "epoch": 2.857142857142857,
      "grad_norm": 1.0208394527435303,
      "learning_rate": 9.904761904761906e-07,
      "loss": 2.5184,
      "step": 500
    },
    {
      "epoch": 2.857142857142857,
      "eval_loss": 2.5099151134490967,
      "eval_runtime": 2.3167,
      "eval_samples_per_second": 17.266,
      "eval_steps_per_second": 8.633,
      "step": 500
    },
    {
      "epoch": 2.914285714285714,
      "grad_norm": 1.0090610980987549,
      "learning_rate": 6.095238095238095e-07,
      "loss": 2.5108,
      "step": 510
    },
    {
      "epoch": 2.9714285714285715,
      "grad_norm": 1.1135526895523071,
      "learning_rate": 2.285714285714286e-07,
      "loss": 2.546,
      "step": 520
    }
  ],
  "logging_steps": 10,
  "max_steps": 525,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 5336102983680000.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
