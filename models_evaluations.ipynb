{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29b03b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc227a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ZS vs REVIEW] Mean Cosine Similarity: 0.6944\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"zero_shot_predictions.csv\")\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "emb_review = model.encode(df[\"review\"].tolist(), convert_to_tensor=True)\n",
    "emb_output = model.encode(df[\"zero_shot_review\"].tolist(), convert_to_tensor=True)\n",
    "\n",
    "cos_scores = util.cos_sim(emb_output, emb_review).diagonal().cpu().numpy()\n",
    "print(f\"[ZS vs REVIEW] Mean Cosine Similarity: {np.mean(cos_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03791896",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluation: Fine-tuned output vs. original human review\n",
    "# Quanto il modello imita lo stile e contenuto delle review originali\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"finetuned_predictions.csv\")\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "emb_review = model.encode(df[\"review\"].tolist(), convert_to_tensor=True)\n",
    "emb_output = model.encode(df[\"generated_review\"].tolist(), convert_to_tensor=True)\n",
    "\n",
    "cos_scores = util.cos_sim(emb_output, emb_review).diagonal().cpu().numpy()\n",
    "print(f\"[FT vs REVIEW] Mean Cosine Similarity: {np.mean(cos_scores):.4f}\")\n",
    "\n",
    "\n",
    "# 2. Zero-shot output vs. original review \n",
    "#Quanto bene il modello base sa già generalizzare senza training\n",
    "df = pd.read_csv(\"zero_shot_predictions.csv\")\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "emb_review = model.encode(df[\"review\"].tolist(), convert_to_tensor=True)\n",
    "emb_output = model.encode(df[\"zero_shot_review\"].tolist(), convert_to_tensor=True)\n",
    "\n",
    "cos_scores = util.cos_sim(emb_output, emb_review).diagonal().cpu().numpy()\n",
    "print(f\"[ZS vs REVIEW] Mean Cosine Similarity: {np.mean(cos_scores):.4f}\")\n",
    "\n",
    "\n",
    "# 3. Fine-tuned output vs. structured review (i.e., the true target)\n",
    "# Quanto bene il modello ha appreso il compito per cui è stato fine-tunato\n",
    "\n",
    "df = pd.read_csv(\"train_structured.csv\")  # contains structured_review\n",
    "df_pred = pd.read_csv(\"finetuned_predictions.csv\")  # contains generated_review\n",
    "\n",
    "# Merge to align outputs with targets\n",
    "merged = pd.merge(df_pred, df[[\"title\", \"structured_review\"]], on=\"title\")\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "emb_target = model.encode(merged[\"structured_review\"].tolist(), convert_to_tensor=True)\n",
    "emb_output = model.encode(merged[\"generated_review\"].tolist(), convert_to_tensor=True)\n",
    "\n",
    "cos_scores = util.cos_sim(emb_output, emb_target).diagonal().cpu().numpy()\n",
    "print(f\"[FT vs STRUCTURED] Mean Cosine Similarity: {np.mean(cos_scores):.4f}\")\n",
    "\n",
    "# 4. Fine-tuned vs. zero-shot output (same input, different model)\n",
    "# Quanto il fine-tuning ha modificato lo stile/output rispetto alla base\n",
    "\n",
    "df_ft = pd.read_csv(\"finetuned_predictions.csv\")\n",
    "df_zs = pd.read_csv(\"zero_shot_predictions.csv\")\n",
    "\n",
    "merged = pd.merge(df_ft, df_zs, on=\"title\")  # align predictions\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "emb_zs = model.encode(merged[\"zero_shot_review\"].tolist(), convert_to_tensor=True)\n",
    "emb_ft = model.encode(merged[\"generated_review\"].tolist(), convert_to_tensor=True)\n",
    "\n",
    "cos_scores = util.cos_sim(emb_ft, emb_zs).diagonal().cpu().numpy()\n",
    "print(f\"[FT vs ZS] Mean Cosine Similarity: {np.mean(cos_scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7519bd14",
   "metadata": {},
   "source": [
    "| **Confronto**                             | **Interpretazione dei valori**                                                                                                                                                        |\n",
    "| ----------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| `generated_review` vs `review`            | **0.6–0.7**: buona fedeltà allo **stile e contenuto umano**, anche se non erano il target diretto. <br>**>0.7**: possibile overfitting stilistico. <br>**<0.5**: troppo diverso.      |\n",
    "| `generated_review` vs `structured_review` | ✅ Questo è il **vero obiettivo del fine-tuning**. <br>**>0.8** = ottimo apprendimento.<br>**0.6–0.8** = sufficiente. <br>**<0.6** = segno che il modello non ha appreso bene il task. |\n",
    "| `zero_shot_review` vs `review`            | Se **simile a `generated_review` vs `review`**, allora il base model già capisce bene. <br>**>0.7**: base model forte. <br>**\\~0.5**: il fine-tuning porta valore.                    |\n",
    "| `generated_review` vs `zero_shot_review`  | **Alta similarità (>0.8)** = il fine-tuning ha cambiato poco lo stile. <br>**Moderata (\\~0.6)** = il modello ha raffinato la risposta. <br>**Bassa (<0.4)** = ha cambiato approccio.  |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
