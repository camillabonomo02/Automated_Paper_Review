{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e102e5f8",
   "metadata": {},
   "source": [
    "# Evaluation Pipeline: Small LLM + LoRA for Automated Paper Review Insights\",\n",
    "\n",
    "This notebook evaluates model outputs (strengths/weaknesses) against human ground-truth in a way **coherent with the project proposal**:\n",
    "- Uses **regression-style metrics** (MSE, RMSE, MAE, R²) on top of text similarity;\n",
    "- Compares **zero-shot** vs **LoRA fine-tuned** models;\n",
    "- Provides two similarity backends:\n",
    "1) **SBERT cosine similarity** (semantic) → recommended;\n",
    "2) **TF-IDF cosine similarity** (offline fallback).\n",
    "\n",
    "Expected CSV columns (auto-detected if named differently):,\n",
    "- `id`, `gt_strengths`, `gt_weaknesses`, `pred_strengths`, `pred_weaknesses`."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
